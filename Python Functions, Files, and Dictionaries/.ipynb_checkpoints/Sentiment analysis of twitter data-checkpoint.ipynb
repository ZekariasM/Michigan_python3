{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment analysis of twitter data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, define a function called strip_punctuation which takes one parameter, a string which represents a word, and removes characters considered punctuation from everywhere in the word. (Hint: remember the .replace() method for strings.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_punctuation(allwords):\n",
    "    punctuation_chars = [\"'\", '\"', \",\", \".\", \"!\", \":\", \";\", '#', '@']\n",
    "    for cha in allwords:\n",
    "        if cha in punctuation_chars:\n",
    "            allwords = allwords.replace(cha, '')\n",
    "    return allwords\n",
    "\n",
    "TwitterData = open(\"project_twitter_data.csv\", \"r\")\n",
    "TwitterWords = TwitterData.read()\n",
    "\n",
    "#print(strip_punctuation(TwitterWords))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, copy in your `strip_punctuation` function and define a function called `get_pos` which takes one parameter, a string which represents one or more sentences, and calculates how many words in the string are considered positive words. Use the list, `positive_words` to determine what words will count as positive. The function should return a positive integer - how many occurrences there are of positive words in the text. Note that all of the words in `positive_words` are lower cased, so you’ll need to convert all the words in the input string to lower case as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation_chars = [\"'\", '\"', \",\", \".\", \"!\", \":\", \";\", '#', '@']\n",
    "# list of positive words to use\n",
    "positive_words = []\n",
    "with open(\"positive_words.txt\") as pos_f:\n",
    "    for lin in pos_f:\n",
    "        if lin[0] != ';' and lin[0] != '\\n':\n",
    "            positive_words.append(lin.strip())\n",
    "\n",
    "\n",
    "def strip_punctuation(allwords):\n",
    "    for cha in allwords:\n",
    "        if cha in punctuation_chars:\n",
    "            allwords = allwords.replace(cha, '')\n",
    "    return allwords\n",
    "\n",
    "#TwitterData = open(\"project_twitter_data.csv\", \"r\")\n",
    "#TwitterWords = TwitterData.read()\n",
    "#print(strip_punctuation(TwitterWords))\n",
    "\n",
    "def get_pos(sentence):\n",
    "    \n",
    "    count=0\n",
    "    \n",
    "    for allwords in sentence.split(\" \"):\n",
    "        if strip_punctuation(allwords) in positive_words:\n",
    "            count = count + 1\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, copy in your strip_punctuation function and define a function called `get_neg` which takes one parameter, a string which represents one or more sentences, and calculates how many words in the string are considered negative words. Use the list, `negative_words` to determine what words will count as negative. The function should return a positive integer - how many occurrences there are of negative words in the text. Note that all of the words in `negative_words` are lower cased, so you’ll need to convert all the words in the input string to lower case as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation_chars = [\"'\", '\"', \",\", \".\", \"!\", \":\", \";\", '#', '@']\n",
    "\n",
    "negative_words = []\n",
    "with open(\"negative_words.txt\") as pos_f:\n",
    "    for lin in pos_f:\n",
    "        if lin[0] != ';' and lin[0] != '\\n':\n",
    "            negative_words.append(lin.strip())\n",
    "\n",
    "\n",
    "def strip_punctuation(allwords):\n",
    "    for cha in allwords:\n",
    "        if cha in punctuation_chars:\n",
    "            allwords = allwords.replace(cha, '')\n",
    "    return allwords\n",
    "\n",
    "\n",
    "def get_pos(sentence):\n",
    "    \n",
    "    count=0\n",
    "    \n",
    "    for allwords in sentence.split(\" \"):\n",
    "        if strip_punctuation(allwords) in positive_words:\n",
    "            count = count + 1\n",
    "    \n",
    "    return count\n",
    "\n",
    "\n",
    "def get_neg(sentence):\n",
    "    \n",
    "    count=0\n",
    "    \n",
    "    for allwords in sentence.split(\" \"):\n",
    "        if strip_punctuation(allwords) in negative_words:\n",
    "            count = count + 1\n",
    "    \n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, copy in your previous functions and write code that opens the file `project_twitter_data.csv` which has the fake generated twitter data (the text of a tweet, the number of retweets of that tweet, and the number of replies to that tweet). Your task is to build a sentiment classifier, which will detect how positive or negative each tweet is. Copy the code from the code windows above, and put that in the top of this code window. Now, you will write code to create a csv file called `resulting_data.csv`, which contains the Number of Retweets, Number of Replies, Positive Score (which is how many happy words are in the tweet), Negative Score (which is how many angry words are in the tweet), and the Net Score (how positive or negative the text is overall) for each tweet. The file should have those headers in that order. Remember that there is another component to this project. You will upload the csv file to Excel or Google Sheets and produce a graph of the Net Score vs Number of Retweets. Check Coursera for that portion of the assignment, if you’re accessing this textbook from Coursera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_data = open(\"project_twitter_data.csv\",\"r\")\n",
    "resulting_data = open(\"resulting_data.csv\",\"w\")\n",
    "\n",
    "punctuation_chars = [\"'\", '\"', \",\", \".\", \"!\", \":\", \";\", '#', '@']\n",
    "\n",
    "negative_words = []\n",
    "with open(\"negative_words.txt\") as pos_f:\n",
    "    for lin in pos_f:\n",
    "        if lin[0] != ';' and lin[0] != '\\n':\n",
    "            negative_words.append(lin.strip())\n",
    "\n",
    "\n",
    "def strip_punctuation(allwords):\n",
    "    for cha in allwords:\n",
    "        if cha in punctuation_chars:\n",
    "            allwords = allwords.replace(cha, '')\n",
    "    return allwords\n",
    "\n",
    "\n",
    "def get_pos(sentence):\n",
    "    \n",
    "    count=0\n",
    "    \n",
    "    for allwords in sentence.split(\" \"):\n",
    "        if strip_punctuation(allwords) in positive_words:\n",
    "            count = count + 1\n",
    "    \n",
    "    return count\n",
    "\n",
    "positive_words = []\n",
    "with open(\"positive_words.txt\") as pos_f:\n",
    "    for lin in pos_f:\n",
    "        if lin[0] != ';' and lin[0] != '\\n':\n",
    "            positive_words.append(lin.strip())\n",
    "            \n",
    "            \n",
    "def get_neg(sentence):\n",
    "    \n",
    "    count=0\n",
    "    \n",
    "    for allwords in sentence.split(\" \"):\n",
    "        if strip_punctuation(allwords) in negative_words:\n",
    "            count = count + 1\n",
    "    \n",
    "    return count\n",
    "\n",
    "negative_words = []\n",
    "with open(\"negative_words.txt\") as pos_f:\n",
    "    for lin in pos_f:\n",
    "        if lin[0] != ';' and lin[0] != '\\n':\n",
    "            negative_words.append(lin.strip())\n",
    "            \n",
    "            \n",
    "            \n",
    "def writingDataFile(resulting_data):\n",
    "    resulting_data.write(\"Number of Retweets, Number of Replies, Positive Score, Negative Score, Net Score\")\n",
    "    resulting_data.write(\"\\n\") \n",
    "    \n",
    "\n",
    "        \n",
    "    linesPTDF =  twitter_data.readlines()\n",
    "    headerDontUsed= linesPTDF.pop(0)\n",
    "    for linesTD in linesPTDF:\n",
    "        listTD = linesTD.strip().split(',')\n",
    "        resulting_data.write(\"{}, {}, {}, {}, {}\".format(listTD[1], listTD[2], get_pos(listTD[0]), get_neg(listTD[0]), (get_pos(listTD[0])-get_neg(listTD[0]))))    \n",
    "        resulting_data.write(\"\\n\")\n",
    "            \n",
    "\n",
    "writingDataFile(resulting_data)\n",
    "\n",
    "#twitter_data.close()\n",
    "#resulting_data.close()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Retweets, Number of Replies, Positive Score, Negative Score, Net Score\n",
      "3, 0, 0, 0, 0\n",
      "1, 0, 2, 2, 0\n",
      "1, 2, 0, 0, 0\n",
      "3, 1, 1, 0, 1\n",
      "6, 0, 2, 0, 2\n",
      "9, 5, 2, 0, 2\n",
      "19, 0, 2, 0, 2\n",
      "0, 0, 0, 3, -3\n",
      "0, 0, 0, 2, -2\n",
      "82, 2, 2, 0, 2\n",
      "0, 0, 0, 1, -1\n",
      "0, 0, 1, 0, 1\n",
      "47, 0, 2, 0, 2\n",
      "2, 1, 1, 0, 1\n",
      "0, 2, 1, 0, 1\n",
      "0, 0, 2, 1, 1\n",
      "4, 6, 3, 0, 3\n",
      "19, 0, 2, 1, 1\n",
      "0, 0, 1, 0, 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = open(\"resulting_data.csv\", 'r')\n",
    "print(x.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
